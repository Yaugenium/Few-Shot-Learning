{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Omniglot_neural_networks_full.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOc4MgeasLf0ExwPLAkomWG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uEssHHPaUcRD"},"source":["# Работа с полным датасетом Omniglot\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"w9QxlSQ_UPQ0"},"source":["# Загрузка полного датасета Omniglot"]},{"cell_type":"markdown","metadata":{"id":"8delerMRUQRb"},"source":["Загрузка датасета"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-B2DrFZtPZfZ","executionInfo":{"status":"ok","timestamp":1620584603219,"user_tz":-180,"elapsed":224836,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}},"outputId":"dda3f08f-f9c8-4f10-ada3-c9cd09e4dcc0"},"source":["from sklearn.metrics import accuracy_score\n","from google.colab import drive\n","\n","import numpy as np\n","import zipfile\n","import io\n","import os\n","\n","NUMBER_OF_CLASSES = 1600\n","PATH = 'drive/My Drive/Few-Shot-Learning/Omniglot-data-set'\n","\n","drive.mount('/content/drive')\n","\n","with zipfile.ZipFile(os.path.join(PATH, 'train_images.zip')) as zipper:\n","    with io.BufferedReader(zipper.open('train_images.txt', mode='r')) as file:\n","        X_train = np.resize(np.loadtxt(file, dtype=np.uint8), (14 * NUMBER_OF_CLASSES, 1, 105, 105))\n","        \n","with zipfile.ZipFile(os.path.join(PATH, 'train_labels.zip')) as zipper:\n","    with io.BufferedReader(zipper.open('train_labels.txt', mode='r')) as file:\n","        y_train = np.resize(np.loadtxt(file, dtype='str'), (14 * NUMBER_OF_CLASSES))\n","        \n","with zipfile.ZipFile(os.path.join(PATH, 'test_images.zip')) as zipper:\n","    with io.BufferedReader(zipper.open('test_images.txt', mode='r')) as file:\n","        X_test = np.resize(np.loadtxt(file, dtype=np.uint8), (6 * NUMBER_OF_CLASSES, 1, 105, 105))\n","        \n","with zipfile.ZipFile(os.path.join(PATH, 'test_labels.zip')) as zipper:\n","    with io.BufferedReader(zipper.open('test_labels.txt', mode='r')) as file:\n","        y_test = np.resize(np.loadtxt(file, dtype='str'), (6 * NUMBER_OF_CLASSES))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XqIB2axQGeD9"},"source":["Определение трансформации"]},{"cell_type":"code","metadata":{"id":"VR9Bg_Rj-MkI","executionInfo":{"status":"ok","timestamp":1620584646902,"user_tz":-180,"elapsed":2982,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}}},"source":["!pip install -q -U albumentations\n","import albumentations as A\n","\n","from albumentations.pytorch import ToTensorV2\n","\n","transform = A.Compose([A.SmallestMaxSize(max_size=105),\n","                       A.CenterCrop(height=84, width=84),\n","                       A.Normalize(mean=(0.5), std=(0.5)),\n","                       ToTensorV2(),])"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZIUnAIMQgn-V"},"source":["Определение тензоров"]},{"cell_type":"code","metadata":{"id":"sVLH1QxQgsUj","executionInfo":{"status":"ok","timestamp":1620584654433,"user_tz":-180,"elapsed":3683,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}}},"source":["import torch\n","\n","train_images = torch.stack([transform(image=x[0])[\"image\"] for x in X_train]).float()\n","test_images = torch.stack([transform(image=x[0])[\"image\"] for x in X_test]).float()\n","\n","classes = [y_train[14 * i] for i in range(NUMBER_OF_CLASSES)]\n","\n","train_labels = torch.from_numpy(np.array([[i] for i in range(NUMBER_OF_CLASSES) for _ in range(14)])).long()\n","test_labels = torch.from_numpy(np.array([[i] for i in range(NUMBER_OF_CLASSES) for _ in range(6)])).long()"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uaB00EAcNpXr"},"source":["Определение вспомогательной функции для подготовки выборки"]},{"cell_type":"code","metadata":{"id":"SEBIgF0SNplC","executionInfo":{"status":"ok","timestamp":1620585217210,"user_tz":-180,"elapsed":598,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}}},"source":["import random\n","\n","def shuffle_tensor(tensor, batch_size, count=14):\n","    random.shuffle(tensor)\n","\n","    images, labels = zip(*tensor)\n","\n","    images = torch.stack(images[:])\n","    labels = torch.stack(labels[:])\n","\n","    images = images.view(count * NUMBER_OF_CLASSES // batch_size, batch_size, 1, 84, 84).float()\n","    labels = labels.view(count * NUMBER_OF_CLASSES // batch_size, batch_size).long()\n","\n","    return list(zip(images, labels))"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V0ZYiV7ONxIN"},"source":["# Визуализация датасета Omniglot (полный датасет)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":349},"id":"khxuQvFPNxza","executionInfo":{"status":"ok","timestamp":1620584669881,"user_tz":-180,"elapsed":557,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}},"outputId":"ec5c3a5e-998c-4596-f48a-1a9238a0c77e"},"source":["from PIL import Image\n","\n","digit_number = -1\n","\n","image = Image.fromarray(X_train[digit_number].reshape(105, 105), mode='P')\n","\n","print('label: {}'.format(y_train[digit_number]))\n","display(image.resize((315, 315)))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["label: ULOG_03\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAATsAAAE7CAMAAACVAtb1AAADAFBMVEUAAAABAQECAgIDAwMEBAQFBQUGBgYHBwcICAgJCQkKCgoLCwsMDAwNDQ0ODg4PDw8QEBARERESEhITExMUFBQVFRUWFhYXFxcYGBgZGRkaGhobGxscHBwdHR0eHh4fHx8gICAhISEiIiIjIyMkJCQlJSUmJiYnJycoKCgpKSkqKiorKyssLCwtLS0uLi4vLy8wMDAxMTEyMjIzMzM0NDQ1NTU2NjY3Nzc4ODg5OTk6Ojo7Ozs8PDw9PT0+Pj4/Pz9AQEBBQUFCQkJDQ0NERERFRUVGRkZHR0dISEhJSUlKSkpLS0tMTExNTU1OTk5PT09QUFBRUVFSUlJTU1NUVFRVVVVWVlZXV1dYWFhZWVlaWlpbW1tcXFxdXV1eXl5fX19gYGBhYWFiYmJjY2NkZGRlZWVmZmZnZ2doaGhpaWlqampra2tsbGxtbW1ubm5vb29wcHBxcXFycnJzc3N0dHR1dXV2dnZ3d3d4eHh5eXl6enp7e3t8fHx9fX1+fn5/f3+AgICBgYGCgoKDg4OEhISFhYWGhoaHh4eIiIiJiYmKioqLi4uMjIyNjY2Ojo6Pj4+QkJCRkZGSkpKTk5OUlJSVlZWWlpaXl5eYmJiZmZmampqbm5ucnJydnZ2enp6fn5+goKChoaGioqKjo6OkpKSlpaWmpqanp6eoqKipqamqqqqrq6usrKytra2urq6vr6+wsLCxsbGysrKzs7O0tLS1tbW2tra3t7e4uLi5ubm6urq7u7u8vLy9vb2+vr6/v7/AwMDBwcHCwsLDw8PExMTFxcXGxsbHx8fIyMjJycnKysrLy8vMzMzNzc3Ozs7Pz8/Q0NDR0dHS0tLT09PU1NTV1dXW1tbX19fY2NjZ2dna2trb29vc3Nzd3d3e3t7f39/g4ODh4eHi4uLj4+Pk5OTl5eXm5ubn5+fo6Ojp6enq6urr6+vs7Ozt7e3u7u7v7+/w8PDx8fHy8vLz8/P09PT19fX29vb39/f4+Pj5+fn6+vr7+/v8/Pz9/f3+/v7////isF19AAAEa0lEQVR4nO3au5LbMBAFUf3/T8OBWS7viqSAvnhR1Z1amBmdQMGWX8Vor9UHPDjteNrxtONpx9OOpx1PO552PO142vEeZvf62eJj1q5vTTuedjzteNrxtONpx9OOpx1PO552PO142vG042nH046nHU87nnY87Xja8bTjacf7Hrv530S7J228OyZ6rB1/rB1/rB1/rB1/rB1/rB1/rB1/vIfdKkTtgmOix9rxx6vt1v7qaRccEz3Wjj/ewG7C0stjosfa8cfa8cer7SZsvDsmeqwdf6wdfzz3m2z1Y1e0i+6JHmvHH8/6Ju9qy+GKdtFV0WPt+OPxX2ZPtb9px9OOt6/dqdo+cEW7JO1429ldke0GV7RL0o63l92D4Ip2SdrxNrJ7FlzRLkk73i52j4Mr2iVpx3uAXTJ2aNrxtOOtt7tR2xmuaJekHW+x3XPhinZJ2vFW2gG4rXC142nHW2B3T6ZdwyvttGt9PMyu78ZBacfTjrejXfeNg9KOpx1vO7vWt8n9YdrxtONtZMfeBuenacfTjjfbLoHDSwelHU873lS7HA4sBVUO1+5uxYePddmhHd9RtSlWA0uHzteOz9eOz59kdwq3oV3Thdp9uPPuwx03Nd2kXdWaK7jd7Fov1O7DnXef77is6SbtIruhS5OZlcO14xdqxy8cbtdRrX4pnqYdn6Ydn7aX3el9E5aCUa1jtdOux6gd7X59MtnYtLRpDpipnXbxnH3t/n04WQeWVg5h07TTLhuywO7/I8I5YCPem6sdc8Cb0zvCOWCjdnzj4+3mF37nUzjtyHPt+HPtyMMQrminHXmoXd0f2t6ehGrH2OTxkrTjacdrtXv/desCV7SLLgnfz087Xi+7DpfkIyanHU87XhPBILVjeK9B09KO9812gw4F84fCFe2iSzrOOiZqxyeOPPd9fv0Z2mnXb379Gdrx/yDe/5K+44p20UTt+MTVdhPUjkX9J2rHJ2rHJ140aH7N9l6rf+/qP1E7PlG7aOh13Yd/3JtvvLxkyFDt+FDtornD+Jrswl0fLhk1Vzs+V7to9G29xlb+04i042nHG7+gt6B22tUs0C7a0ZVPO+0qd2iXbuokOBno7pJ5m7Tjm7SLllXUOmTC2ZeXTF2mHV+mXboyE9ROO7ZSu3Qx5dNOu2SxdtHumG/mtSdnrNytHd+tXXoB4tuh9cdpF1ygXZ52PO142kVpx9OOp13aI+CKdkk73qfd96cdTzuedjzteNrxtONpx9OOpx1PO552PO142vG042nH046nHU87nnY87Xja8bTjacfTjqcdTzuedjzteNrxtONpx9OOpx1PO552PO142vG042nH046nHU87nnY87Xja8bTjacfTjqcdTzuedjzteNrxtONpx9OOpx1PO552PO142vG042nH046nHU87nnY87Xja8bTjacfTjqcdTzuedjzteNrxtONpx9OOpx1PO552PO142vG042nH046nHU87nnY87Xja8bTjacfTjqcdTzveH5jpjKsjhtbOAAAAAElFTkSuQmCC\n","text/plain":["<PIL.Image.Image image mode=P size=315x315 at 0x7F737050E090>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"M5TM3L5AW_MB"},"source":["# Использование полносвязной нейронной сети для решения задачи классификации рукописных символов (полный датасет)"]},{"cell_type":"markdown","metadata":{"id":"NzXm4wW7W_rR"},"source":["Создание полносвязной нейронной сети"]},{"cell_type":"code","metadata":{"id":"gJrD-rDit1W9","executionInfo":{"status":"ok","timestamp":1620591374702,"user_tz":-180,"elapsed":533,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.drop = nn.Dropout(p=0.2)\n","        self.fc1 = nn.Linear(84 * 84, 3600)\n","        self.fc2 = nn.Linear(3600, 2000)\n","        self.fc3 = nn.Linear(2000, 1600)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 84 * 84)\n","        x = F.relu(self.drop(self.fc1(x)))\n","        x = F.relu(self.drop(self.fc2(x)))\n","        x = self.fc3(x)\n","        return x"],"execution_count":88,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eigT7r3fvTpT"},"source":["Обучение полносвязной нейронной сети"]},{"cell_type":"code","metadata":{"id":"9SZ4KSBzvVtT"},"source":["import torch.optim as optim\n","\n","net = Net().cuda()\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n","\n","for iteration in range(800):\n","    trainset = shuffle_tensor(list(zip(train_images, train_labels)), 400)\n","\n","    for data in trainset:\n","        images, labels = data[0].cuda(), data[1].cuda()\n","\n","        optimizer.zero_grad()\n","\n","        labels_pred = net(images.unsqueeze(0))\n","        loss = criterion(labels_pred, labels)\n","\n","        loss.backward()\n","        optimizer.step()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_6G2Q7PeLrcT"},"source":["Использование полносвязной нейронной сети"]},{"cell_type":"code","metadata":{"id":"AAvpMt4RYvjy","executionInfo":{"status":"ok","timestamp":1620593021194,"user_tz":-180,"elapsed":1106,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}}},"source":["labels_pred = []\n","labels_true = []\n","\n","net.eval()\n","\n","testset = shuffle_tensor(list(zip(test_images, test_labels)), 400, 6)\n","\n","for data in testset:\n","    images, labels = data[0].cuda(), data[1].cuda()\n","\n","    labels_pred.append(net(images.unsqueeze(0)).cpu().detach().numpy())\n","    labels_true.append(labels.cpu().detach().numpy())\n","\n","labels_pred = np.reshape(np.array(labels_pred), (6 * NUMBER_OF_CLASSES, -1))\n","labels_true = np.reshape(np.array(labels_true), (-1))\n","\n","predicted = np.argmax(labels_pred, axis=1)"],"execution_count":99,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GWAXXFsKiBZm"},"source":["Вычисление метрик"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yup93gbGiBhz","executionInfo":{"status":"ok","timestamp":1620593023384,"user_tz":-180,"elapsed":534,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}},"outputId":"3803bc1e-0ff5-4736-d8e0-46abd5f747b1"},"source":["print('accuracy {:.3}'.format(accuracy_score(labels_true, predicted)))"],"execution_count":100,"outputs":[{"output_type":"stream","text":["accuracy 0.36\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OAdozHcOpiTH"},"source":["# Использование сверточной нейронной сети для решения задачи классификации рукописных символов (полный датасет)"]},{"cell_type":"markdown","metadata":{"id":"mmGoswhmpiTR"},"source":["Создание сверточной нейронной сети"]},{"cell_type":"code","metadata":{"id":"K4NAUV_2piTS","executionInfo":{"status":"ok","timestamp":1620587979968,"user_tz":-180,"elapsed":679,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 16, 3)\n","        self.conv2 = nn.Conv2d(16, 32, 3)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.bnorm1 = nn.BatchNorm2d(16)\n","        self.bnorm2 = nn.BatchNorm2d(32)\n","        self.drop = nn.Dropout(p=0.2)\n","        self.fc1 = nn.Linear(32 * 19 * 19, 3600)\n","        self.fc2 = nn.Linear(3600, 1600)\n","\n","    def forward(self, x):\n","        x = F.relu(self.bnorm1(self.pool(self.conv1(x))))\n","        x = F.relu(self.bnorm2(self.pool(self.conv2(x))))\n","        x = x.view(-1, 32 * 19 * 19)\n","        x = F.relu(self.drop(self.fc1(x)))\n","        x = self.fc2(x)\n","        return x"],"execution_count":60,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rJ9M01kWpiTT"},"source":["Обучение сверточной нейронной сети"]},{"cell_type":"code","metadata":{"id":"qRWgG6LYpiTT"},"source":["import torch.optim as optim\n","\n","net = Net().cuda()\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n","\n","for iteration in range(400):\n","    trainset = shuffle_tensor(list(zip(train_images, train_labels)), 400)\n","\n","    for data in trainset:\n","        images, labels = data[0].cuda(), data[1].cuda()\n","\n","        optimizer.zero_grad()\n","\n","        labels_pred = net(images)\n","        loss = criterion(labels_pred, labels)\n","\n","        loss.backward()\n","        optimizer.step()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HUE63YV1piTU"},"source":["Использование сверточной нейронной сети"]},{"cell_type":"code","metadata":{"id":"Gcjpl4tlpiTU","executionInfo":{"status":"ok","timestamp":1620591313234,"user_tz":-180,"elapsed":1359,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}}},"source":["labels_pred_s = []\n","labels_true_s = []\n","\n","net.eval()\n","\n","testset = shuffle_tensor(list(zip(test_images, test_labels)), 400, 6)\n","\n","for data in testset:\n","    images, labels = data[0].cuda(), data[1].cuda()\n","\n","    labels_pred_s.append(net(images).cpu().detach().numpy())\n","    labels_true_s.append(labels.cpu().detach().numpy())\n","\n","labels_pred_s = np.reshape(np.array(labels_pred_s), (6 * NUMBER_OF_CLASSES, -1))\n","labels_true_s = np.reshape(np.array(labels_true_s), (-1))\n","\n","predicted_s = np.argmax(labels_pred_s, axis=1)"],"execution_count":86,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZJK0QXn0piTV"},"source":["Вычисление метрик"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zGqq25fDpiTV","executionInfo":{"status":"ok","timestamp":1620591314780,"user_tz":-180,"elapsed":528,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}},"outputId":"6122b3fc-dbba-4036-f2e4-12b24687f549"},"source":["print('accuracy {:.3}'.format(accuracy_score(labels_true_s, predicted_s)))"],"execution_count":87,"outputs":[{"output_type":"stream","text":["accuracy 0.45\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qFGQc7rFIbMV"},"source":["# Сравнение результатов работы нейронных сетей для уменьшенного и полного датасета Omniglot"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E8eSXXkJcm-H","executionInfo":{"status":"ok","timestamp":1620593067657,"user_tz":-180,"elapsed":529,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}},"outputId":"c92e912d-a026-45ab-b6bd-eda17cba4f04"},"source":["from sklearn.metrics import accuracy_score\n","\n","print('Neural network accuracy              : {:.3}'.format(accuracy_score(labels_true, predicted)))\n","print('Convolutional Neural network accuracy: {:.3}'.format(accuracy_score(labels_true_s, predicted_s)))"],"execution_count":101,"outputs":[{"output_type":"stream","text":["Neural network accuracy              : 0.36\n","Convolutional Neural network accuracy: 0.45\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pUiuyl4jJQtO"},"source":["Как показывают результаты выше, увеличение числа классов в задаче классификации в 16 раз отнюдь не прошло бесследно. Но стоит отметить, что даже при таком глобальном масштабировании условия задачи, итоговые результаты хоть и просели, но показывают завидные показатели для такой задачи. В целом сложно что-то сказать об успешности эксперимента и данные две модели будут использованы в качестве байзлайна для дальнейших исследований."]}]}