{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Omniglot_neural_networks_V2.ipynb","provenance":[{"file_id":"1fNzdMzJmbsnnqjqrV9W-HnPrZ9MPtlsy","timestamp":1616926115423}],"collapsed_sections":["w9QxlSQ_UPQ0","V0ZYiV7ONxIN","M5TM3L5AW_MB","OAdozHcOpiTH"],"authorship_tag":"ABX9TyOE/7IZjtr53lsUYNay1s9L"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uEssHHPaUcRD"},"source":["# Работа с уменьшенным датасетом Omniglot\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"w9QxlSQ_UPQ0"},"source":["# Загрузка уменьшенного датасета Omniglot"]},{"cell_type":"markdown","metadata":{"id":"8delerMRUQRb"},"source":["Загрузка датасета"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-B2DrFZtPZfZ","executionInfo":{"status":"ok","timestamp":1616941440090,"user_tz":-180,"elapsed":83769,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}},"outputId":"e0a7b241-30e8-42a5-a44c-ebb58f4470a4"},"source":["from sklearn.metrics import accuracy_score\n","from google.colab import drive\n","import numpy as np\n","import os\n","\n","drive.mount('/content/drive')\n","\n","PATH = 'drive/My Drive/Few-Shot-Learning/Omniglot-data-set'\n","\n","RANDOM_STATE = 17\n","NUMBER_OF_CLASSES = 100\n","AUGMENTATION_COUNT = 10\n","\n","X_train_r = np.resize(np.loadtxt(os.path.join(PATH, 'train_images.txt'), dtype=np.uint8), (14 * NUMBER_OF_CLASSES, 1, 105, 105))\n","y_train_r = np.resize(np.loadtxt(os.path.join(PATH, 'train_labels.txt'), dtype='str'), (14 * NUMBER_OF_CLASSES))\n","\n","X_test_r = np.resize(np.loadtxt(os.path.join(PATH, 'test_images.txt'), dtype=np.uint8), (6 * NUMBER_OF_CLASSES, 1, 105, 105))\n","y_test_r = np.resize(np.loadtxt(os.path.join(PATH, 'test_labels.txt'), dtype='str'), (6 * NUMBER_OF_CLASSES))"],"execution_count":99,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XqIB2axQGeD9"},"source":["Определение аугментации"]},{"cell_type":"code","metadata":{"id":"VR9Bg_Rj-MkI","executionInfo":{"status":"ok","timestamp":1616941514300,"user_tz":-180,"elapsed":3023,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}}},"source":["!pip install -q -U albumentations\n","import albumentations as A\n","\n","from albumentations.pytorch import ToTensorV2\n","\n","train_transform = A.Compose([A.SmallestMaxSize(max_size=105),\n","                             A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n","                             A.RandomCrop(height=84, width=84),\n","                             A.Normalize(mean=(0.5), std=(0.5)),\n","                             ToTensorV2(),])\n","\n","test_transform = A.Compose([A.SmallestMaxSize(max_size=105),\n","                            A.CenterCrop(height=84, width=84),\n","                            A.Normalize(mean=(0.5), std=(0.5)),\n","                            ToTensorV2(),])"],"execution_count":103,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H3whmknTOixN"},"source":["Определение тензоров с применением аугментации"]},{"cell_type":"code","metadata":{"id":"Z_h_uzVOKDpj","executionInfo":{"status":"ok","timestamp":1616942536380,"user_tz":-180,"elapsed":2773,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}}},"source":["import torch\n","\n","train_images = torch.stack([train_transform(image=x[0])[\"image\"] for x in X_train_r for _ in range(AUGMENTATION_COUNT)]).float()\n","test_images = torch.stack([test_transform(image=x[0])[\"image\"] for x in X_test_r]).float()\n","\n","classes = [y_train_r[14 * i] for i in range(NUMBER_OF_CLASSES)]\n","\n","train_labels = torch.from_numpy(np.array([[i] for i in range(NUMBER_OF_CLASSES) for _ in range(14 * AUGMENTATION_COUNT)])).long()\n","test_labels = torch.from_numpy(np.array([[i] for i in range(NUMBER_OF_CLASSES) for _ in range(6)])).long()"],"execution_count":122,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uaB00EAcNpXr"},"source":["Определение вспомогательной функции для подготовки выборки"]},{"cell_type":"code","metadata":{"id":"SEBIgF0SNplC","executionInfo":{"status":"ok","timestamp":1616942542706,"user_tz":-180,"elapsed":534,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}}},"source":["import random\n","\n","def shuffle_tensor(tensor, batch_size):\n","    random.shuffle(tensor)\n","\n","    images, labels = zip(*tensor)\n","\n","    images = torch.stack(images[:])\n","    labels = torch.stack(labels[:])\n","\n","    images = images.view(14 * NUMBER_OF_CLASSES * AUGMENTATION_COUNT // batch_size, batch_size, 1, 84, 84).float()\n","    labels = labels.view(14 * NUMBER_OF_CLASSES * AUGMENTATION_COUNT // batch_size, batch_size).long()\n","\n","    return list(zip(images, labels))"],"execution_count":123,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V0ZYiV7ONxIN"},"source":["# Визуализация датасета Omniglot (уменьшенный датасет)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":349},"id":"khxuQvFPNxza","executionInfo":{"status":"ok","timestamp":1616942544572,"user_tz":-180,"elapsed":561,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}},"outputId":"4f99520b-4416-40c0-cf07-774d563b83c0"},"source":["from PIL import Image\n","\n","digit_number = -1\n","\n","image = Image.fromarray(X_train_r[digit_number].reshape(105, 105), mode='P')\n","\n","print('label: {}'.format(y_train_r[digit_number]))\n","display(image.resize((315, 315)))"],"execution_count":124,"outputs":[{"output_type":"stream","text":["label: Armenian_05\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<PIL.Image.Image image mode=P size=315x315 at 0x7FDFB2342150>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"M5TM3L5AW_MB"},"source":["# Использование полносвязной нейронной сети для решения задачи классификации рукописных символов (уменьшенный датасет, аугментация выборки)"]},{"cell_type":"markdown","metadata":{"id":"NzXm4wW7W_rR"},"source":["Создание полносвязной нейронной сети"]},{"cell_type":"code","metadata":{"id":"gJrD-rDit1W9","executionInfo":{"status":"ok","timestamp":1616942547097,"user_tz":-180,"elapsed":662,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.drop = nn.Dropout(p=0.2)\n","        self.fc1 = nn.Linear(84 * 84, 1000)\n","        self.fc2 = nn.Linear(1000, 500)\n","        self.fc3 = nn.Linear(500, 100)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 84 * 84)\n","        x = F.relu(self.drop(self.fc1(x)))\n","        x = F.relu(self.drop(self.fc2(x)))\n","        x = self.fc3(x)\n","        return x"],"execution_count":125,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eigT7r3fvTpT"},"source":["Обучение полносвязной нейронной сети"]},{"cell_type":"code","metadata":{"id":"9SZ4KSBzvVtT"},"source":["import torch.optim as optim\n","\n","net = Net()\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n","\n","for iteration in range(100):\n","    trainset = shuffle_tensor(list(zip(train_images, train_labels)), 50)\n","\n","    for data in trainset:\n","        images, labels = data\n","\n","        optimizer.zero_grad()\n","\n","        labels_pred = net(images.unsqueeze(0))\n","        loss = criterion(labels_pred, labels)\n","\n","        loss.backward()\n","        optimizer.step()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_6G2Q7PeLrcT"},"source":["Использование полносвязной нейронной сети"]},{"cell_type":"code","metadata":{"id":"XVoVwIKv-NYI","executionInfo":{"status":"ok","timestamp":1616952241721,"user_tz":-180,"elapsed":976,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}}},"source":["labels_pred = net(test_images)\n","_, predicted = torch.max(labels_pred, 1)"],"execution_count":171,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GWAXXFsKiBZm"},"source":["Вычисление метрик"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yup93gbGiBhz","executionInfo":{"status":"ok","timestamp":1616952243650,"user_tz":-180,"elapsed":893,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}},"outputId":"534b8060-d43e-4c57-a4b4-139aa61e6421"},"source":["print('accuracy {:.3}'.format(accuracy_score(test_labels.detach().numpy().T[0], predicted.detach().numpy())))"],"execution_count":172,"outputs":[{"output_type":"stream","text":["accuracy 0.775\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OAdozHcOpiTH"},"source":["# Использование сверточной нейронной сети для решения задачи классификации рукописных символов (уменьшенный датасет, аугментация выборки)"]},{"cell_type":"markdown","metadata":{"id":"mmGoswhmpiTR"},"source":["Создание сверточной нейронной сети"]},{"cell_type":"code","metadata":{"id":"K4NAUV_2piTS","executionInfo":{"status":"ok","timestamp":1616952716528,"user_tz":-180,"elapsed":544,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class Net(nn.Module):\n","  def __init__(self):\n","    super(Net, self).__init__()\n","    self.conv1 = nn.Conv2d(1, 16, 3)\n","    self.conv2 = nn.Conv2d(16, 32, 3)\n","    self.pool = nn.MaxPool2d(2, 2)\n","    self.bnorm1 = nn.BatchNorm2d(16)\n","    self.bnorm2 = nn.BatchNorm2d(32)\n","    self.drop = nn.Dropout(p=0.2)\n","    self.fc1 = nn.Linear(32 * 19 * 19, 1000)\n","    self.fc2 = nn.Linear(1000, 100)\n","\n","  def forward(self, x):\n","    x = F.relu(self.bnorm1(self.pool(self.conv1(x))))\n","    x = F.relu(self.bnorm2(self.pool(self.conv2(x))))\n","    x = x.view(-1, 32 * 19 * 19)\n","    x = F.relu(self.drop(self.fc1(x)))\n","    x = self.fc2(x)\n","    return x\n"],"execution_count":180,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rJ9M01kWpiTT"},"source":["Обучение сверточной нейронной сети"]},{"cell_type":"code","metadata":{"id":"qRWgG6LYpiTT"},"source":["import torch.optim as optim\n","\n","net = Net()\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n","\n","for iteration in range(10):\n","    trainset = shuffle_tensor(list(zip(train_images, train_labels)), 50)\n","\n","    for data in trainset:\n","        images, labels = data\n","\n","        optimizer.zero_grad()\n","\n","        labels_pred = net(images)\n","        loss = criterion(labels_pred, labels)\n","\n","        loss.backward()\n","        optimizer.step()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HUE63YV1piTU"},"source":["Использование сверточной нейронной сети"]},{"cell_type":"code","metadata":{"id":"Gcjpl4tlpiTU","executionInfo":{"status":"ok","timestamp":1616954232528,"user_tz":-180,"elapsed":1444,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}}},"source":["labels_pred_s = net(test_images)\n","_, predicted_s = torch.max(labels_pred_s, 1)"],"execution_count":184,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZJK0QXn0piTV"},"source":["Вычисление метрик"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zGqq25fDpiTV","executionInfo":{"status":"ok","timestamp":1616954233823,"user_tz":-180,"elapsed":572,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}},"outputId":"526eceb1-1c1c-42fd-98e2-86e09f5e0c64"},"source":["print('accuracy {:.3}'.format(accuracy_score(test_labels.detach().numpy().T[0], predicted_s.detach().numpy())))"],"execution_count":185,"outputs":[{"output_type":"stream","text":["accuracy 0.908\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qFGQc7rFIbMV"},"source":["# Сравнение результатов работы нейронных сетей с классическими методами машинного обучения для датасета Omniglot (уменьшенный датасет, аугментация выборки)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E8eSXXkJcm-H","executionInfo":{"status":"ok","timestamp":1616954254841,"user_tz":-180,"elapsed":538,"user":{"displayName":"Евгений Ганкович","photoUrl":"","userId":"00683877056076929865"}},"outputId":"1e748a1b-456d-410c-db97-f59c4ff5a042"},"source":["from sklearn.metrics import accuracy_score\n","\n","print('Neural network accuracy              : {:.3}'.format(accuracy_score(test_labels.detach().numpy().T[0], predicted.detach().numpy())))\n","print('Convolutional Neural network accuracy: {:.3}'.format(accuracy_score(test_labels.detach().numpy().T[0], predicted_s.detach().numpy())))"],"execution_count":186,"outputs":[{"output_type":"stream","text":["Neural network accuracy              : 0.775\n","Convolutional Neural network accuracy: 0.908\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pUiuyl4jJQtO"},"source":["Аугментация выборки дала ощутимый прирост к итоговой метрике качества. По сравнению с использованием обычной выборки без искусственного ее увеличения данная техника позволила получить результаты в полтора раза лучше. Следует отметить, что хоть и параметры подбирались тщательным образом, при лучшей настройке можно получить более высокие результаты. Пространством для маневра тут является как и ахритектура нейронных сетей и ее обучение, так и подбор параметров аугментации."]}]}